# ==============================================================================
#  Prometheus Agent Environment Configuration (v2.0 - Hybrid LLM)
# ==============================================================================
#
# INSTRUCTIONS:
# 1. RENAME this file to `.env`.
# 2. Configure the LLM_PROVIDER section first.
# 3. Fill in the required API keys and settings for your chosen provider.
# 4. NEVER commit the `.env` file to a public version control system.
#
# ==============================================================================


# --- LLM PROVIDER CONFIGURATION (CRITICAL) ---

# [REQUIRED] Choose the source of the agent's reasoning.
# Options:
#   "openai" - Uses the OpenAI API cloud service (requires OPENAI_API_KEY).
#   "local"  - Uses a local LLM server (like Ollama) that provides an
#              OpenAI-compatible API endpoint.
LLM_PROVIDER="local"


# --- LOCAL LLM SERVER SETTINGS (Only used if LLM_PROVIDER="local") ---

# [REQUIRED FOR LOCAL] The base URL of your local LLM server.
# Ollama's default is http://localhost:11434/v1
# LM Studio's default is http://localhost:1234/v1
LOCAL_API_BASE_URL="http://localhost:11434/v1"

# [REQUIRED FOR LOCAL] The exact model name as registered in your local server.
# For Ollama, this is the name you used in `ollama pull`.
# Example: "llama3:70b", "mistral", "codellama"
LOCAL_MODEL_NAME="llama3:70b"


# --- CLOUD API KEYS (Only used if LLM_PROVIDER="openai") ---

# [REQUIRED FOR OPENAI] Your OpenAI API Key.
# If using a local model, this can be left blank or set to a dummy value
# like "not_needed", as some local servers require a non-empty key.
OPENAI_API_KEY="not_needed"


# --- VOICE & AVATAR API KEYS (OPTIONAL) ---
ELEVENLABS_API_KEY="YourElevenLabsAPI_KeyGoesHere"


# --- ADVANCED QUANTUM COMPUTING (OPTIONAL) ---
IBM_QUANTUM_API_TOKEN="8ef935bf58677eb36e465ca1bb10508a5092d4c9c2d31c251b4fcae88ac94ffdea741d58a9c2217fb37d384109cda4b6a385e6ddbc3dec12af25e248ea12bede"